{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TÉCNICAS AVANZADAS DE CLASIFICACIÓN\n",
    "\n",
    "En la sesión de hoy vamos a trabajar con metodologías basadas en boosting y svm para clasificación.\n",
    "\n",
    "Vamos a trabajar con el problema de clasificación que hemos estado trabajando en las sesiones pasadas (de forma que se puedan comparar resultados).\n",
    "\n",
    "\n",
    "### TÉCNICAS DE BOOSTING PARA CLASIFICACIÓN\n",
    "\n",
    "Los métodos de boosting que vamos a probar son adaboost y las implementaciones (ligeramente) diferentes de gradient boosting que hemos visto en clase, xgboost, catboost y lightgbm.\n",
    "\n",
    "\n",
    "Puede que tengas que instalar las librerías. Si es el caso, descomenta la línea que está relacionada con la librería que no tienes instalada en tu portátil.\n",
    "\n",
    "Tanto xgboost como lightgbm están instaladas por defecto en Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org xgboost \n",
    "#! pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org catboost \n",
    "#! pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos dicho, para el problema de clasificación vamos a utilizar el conjunto de datos de diabetes que ya utilizamos en una sesión anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "file_name='Diabetes.csv'\n",
    "path_file = os.path.join(current_dir, f\"../data/{file_name}\")\n",
    "df_diabetes=pd.read_csv(path_file, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hicimos en la clase anterior, tenemos que rellenar los valores no válidos de las siguientes columnas 'GLUCOSE','BLOODPRESS','SKINTHICKNESS','INSULIN','BODYMASSINDEX','PEDIGREEFUNC' o 'AGE'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a dividir el dataset general en un conjunto de datos de entrenamiento (con un 70% de los datos) y un conjunto de datos de test. Asegúrese de que tanto el conjunto de datos de entrenamiento como el de prueba están estratificados en función del valor de la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x=df_diabetes.iloc[:,:-1]\n",
    "y=df_diabetes.iloc[:,-1]\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0,shuffle=True,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "def Metrics(y_true,y_pred,data='train'):\n",
    "    print('The metrics for the {} dataset are:'.format(data))\n",
    "    print('Precision: %.3f' % precision_score(y_true, y_pred))\n",
    "    print('Recall: %.3f' % recall_score(y_true, y_pred))\n",
    "    print('Accuracy: %.3f' % accuracy_score(y_true, y_pred))\n",
    "    print('F1 Score: %.3f' % f1_score(y_true, y_pred))\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "def plot_cm(test_y,predicted):\n",
    "    \n",
    "    cm=confusion_matrix(y_true=test_y,y_pred=predicted)\n",
    "    plt.figure(figsize=(9,9))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r',cbar=False);\n",
    "    plt.ylabel('Actual label');\n",
    "    plt.xlabel('Predicted label');\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADABOOST\n",
    "El primer método de boosting que vamos a probar es un enfoque adaboost. En este caso, definiremos un árbol de decisión con 5 capas, un mínimo de 10 muestras por nodo y un máximo de 15 nodos por hoja como estimador base. Defina un modelo global con 50 estimadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compruebe las métricas de los conjuntos de datos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cree que su modelo está infra-ajustado o sobreajustado? \n",
    "\n",
    "Realice un ajuste de hiperparámetros para definir el conjunto de hiperparámetros que mejor se ajuste a su problema. Utilice un esquema de validación cruzada de 5 folds.\n",
    "\n",
    "- 'n_estimators':[25,50]\n",
    "\n",
    "Y defina un estimador individual que intente superar el problema (o sobre o infra ajuste) que crea que presenta su modelo.\n",
    "\n",
    "Una vez que haya entrenado su modelo, compruebe las características del mejor estimador y analice su rendimiento con los conjuntos de datos de entrenamiento y de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dibuje una figura que evalúe la \"importancia\" de cada característica dentro de este mejor estimador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBOOST\n",
    "\n",
    "La siguiente técnica que vamos a probar es gradient boosting. La primera implementación que vamos a probar será XGBOOST. En este caso, el primer modelo xgboost que vamos a evaluar tendrá 150 rondas, un eta de 0.5, una profundidad máxima de 5, un lambda de 1.5 y un alpha de 0.5. Deberá definir un objetivo que se ajuste a nuestro problema específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras analizar los resultados obtenidos, ¿cree que su modelo está infra o sobreajustado? \n",
    "\n",
    "Realice un ajuste de hiperparámetros para definir el conjunto de hiperparámetros que mejor se ajustan a su problema. Utilice un esquema de validación cruzada de 5 pliegues teniendo en cuenta los resultados que acaba de obtener.\n",
    "\n",
    "- n_estimators':[100,150]\n",
    "- reg_alpha':[0.5,1.5,5]\n",
    "- reg_lambda':[1,1.5,3]\n",
    "- max_depth':[3,5,7]\n",
    "\n",
    "\n",
    "Una vez entrenado el modelo, compruebe las características del mejor estimador y analiza su rendimiento con los conjuntos de datos de entrenamiento y de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost\n",
    "\n",
    "La segunda implementación de gradient boosting que vamos a probar será catboost. En este caso, el primer modelo catboost que vamos a evaluar tendrá 100 iteraciones, un eta de 0,5, una profundidad máxima de 3 y un lambda de 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compruebe su rendimiento y analice si considera que puede estar sobreajustándose al problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realice un ajuste de hiperparámetros para definir el conjunto de hiperparámetros que mejor se adapte a su problema. Utilice un esquema de validación cruzada de 5 folds teniendo en cuenta los resultados que acabas de obtener.\n",
    "\n",
    "- 'iterations':[50,100,150]\n",
    "- 'depth':[3,5,7,10]\n",
    "- 'min_data_in_leaf':[5,10,15]\n",
    "- eta':[0,0.5,0.7,1.5]\n",
    "\n",
    "Una vez entrenado el modelo, compruebe las características del mejor estimador y analice su rendimiento con los conjuntos de datos de entrenamiento y de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lightgbm\n",
    "Ahora vamos a definir un modelo lightgbm con 100 estimadores con una max_profundidad de 5 capas y 35 como máximo de hojas del árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realice un ajuste de hiperparámetros para definir el conjunto de hiperparámetros que mejor se adapte a su problema. Utilice un esquema de validación cruzada de 5 pliegues.\n",
    "\n",
    "- 'iterations':[50,100,150]\n",
    "- 'depth':[3,5,7]\n",
    "- 'alpha':[0,1.5,3]\n",
    "\n",
    "\n",
    "Una vez que hayas entrenado tu modelo, comprueba las características del mejor estimador y analiza su rendimiento tanto con el conjunto de datos de entrenamiento como con el de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Máquina de soporte vector\n",
    "Por último, vamos a probar varios clasificadores de máquina de soporte vector. El primero tendrá un kernel de base radial con C igual a 4. No olvides normalizar previamente el conjunto de entrenamiento (y aplicar la misma operación al conjunto de prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compruebe ahora si se comporta mejor un kernel polinomial con 3,4 ó 5 grados o una base radial con una gamma aut o scale o con una C igual a 1, 5 ó 10. Utilice un CV de 5 folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
